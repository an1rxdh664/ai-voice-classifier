ğŸ™ï¸ AI Voice Classifier
ğŸ“Œ Project Overview

AI Voice Classifier is a backend system designed to detect whether an audio sample is human voice or AI-generated voice using machine learning and audio signal processing.

The system exposes a FastAPI REST endpoint where users upload an audio file. The backend processes the file, extracts audio features, runs them through a trained ML model, and returns:

Prediction (AI or Human)

Confidence Score

This project is built for real-world scenarios like:

Deepfake detection

Voice authentication validation

AI content moderation

Security & fraud prevention

âš™ï¸ How The System Works
ğŸ§  Stage 1 â€” Training Pipeline

Audio datasets are stored in:

data/ai/

data/human/

Audio is processed using Librosa to extract:

MFCC (Mel Frequency Cepstral Coefficients)

Pitch

Spectral Features

Energy Features

Extracted features are used to train a ML model:

Example: Random Forest Classifier

Two important artifacts are saved:

model.pkl â†’ Trained ML model

scaler.pkl â†’ Feature normalizer

ğŸš€ Stage 2 â€” Prediction Pipeline

User uploads audio to FastAPI endpoint

Server:

Loads trained model + scaler

Extracts same features from uploaded audio

Scales features

Runs prediction

API returns:

{
  "prediction": "AI",
  "confidence": 0.92
}

ğŸ“‚ Project Structure
ai-voice-classifier/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ ai/
â”‚   â”‚   â””â”€â”€ insert_ai_data.txt
â”‚   â”œâ”€â”€ human/
â”‚   â”‚   â””â”€â”€ insert_human_data.txt
â”‚
â”œâ”€â”€ model/
â”‚   â”œâ”€â”€ model.pkl        # Trained classifier
â”‚   â””â”€â”€ scaler.pkl       # Feature scaler
â”œâ”€â”€ app.py               # FastAPI application
â”œâ”€â”€ extract.py           # Feature extraction
â”œâ”€â”€ model.py             # Model training
â”œâ”€â”€ predict_utils.py     # Prediction logic
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore

ğŸ“„ File Responsibilities
ğŸ”¹ app.py

FastAPI server entry point
Handles:

API routes

File upload handling

Calling prediction pipeline

ğŸ”¹ extract.py

Handles audio feature extraction:

Loads audio using Librosa

Extracts MFCC, pitch, spectral, energy features

Converts audio â†’ numerical feature vector

ğŸ”¹ model.py

Training pipeline:

Loads dataset

Trains ML model

Saves:

model.pkl

scaler.pkl

ğŸ”¹ predict_utils.py

Prediction helper logic:

Loads saved model + scaler

Prepares input features

Returns prediction + confidence

ğŸ§ª Tech Stack
Backend

FastAPI

Python

Machine Learning

Scikit-Learn

Librosa

NumPy

Pandas

Joblib / Pickle

ğŸ“¦ Installation & Setup
1ï¸âƒ£ Clone Repository
git clone https://github.com/YOUR_USERNAME/ai-voice-classifier.git
cd ai-voice-classifier

2ï¸âƒ£ Create Virtual Environment
python -m venv venv


Activate:

Windows:

venv\Scripts\activate


Linux / Mac:

source venv/bin/activate

3ï¸âƒ£ Install Dependencies
pip install -r requirements.txt

â–¶ï¸ Running The Server
uvicorn app:app --reload


Server runs at:

http://127.0.0.1:8000


Swagger Docs:

http://127.0.0.1:8000/docs

ğŸ“¡ API Usage
Upload Audio For Prediction

Endpoint

POST /predict


Request

Form Data

Key: file

Value: Audio File (.wav recommended)

Example Response
{
  "prediction": "Human",
  "confidence": 0.87
}

ğŸ§¬ Model Details
Component	Purpose
Feature Extraction	Converts audio â†’ numerical signals
Scaler	Normalizes feature values
ML Model	Classifies voice type
ğŸ“Š Future Improvements

Add Deep Learning Models (CNN / LSTM)

Support More Languages

Real-time Streaming Detection

Docker Deployment

Cloud Hosting (AWS / GCP)

ğŸ”’ Security Considerations

Validate file type

Limit upload size

Add API authentication

Rate limiting

ğŸ¤ Contributing

Contributions are welcome.

Steps:

Fork repository

Create feature branch

Commit changes

Open Pull Request


â­ If You Like This Project

Give it a star on GitHub.